{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafe509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4497b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(100)\n",
    "\n",
    "### Data Preprocessing ###\n",
    "\n",
    "dataset = pd.read_csv('financial_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b04ba2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>age</th>\n",
       "      <th>pay_schedule</th>\n",
       "      <th>home_owner</th>\n",
       "      <th>income</th>\n",
       "      <th>months_employed</th>\n",
       "      <th>years_employed</th>\n",
       "      <th>current_address_year</th>\n",
       "      <th>personal_account_m</th>\n",
       "      <th>personal_account_y</th>\n",
       "      <th>...</th>\n",
       "      <th>amount_requested</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>risk_score_2</th>\n",
       "      <th>risk_score_3</th>\n",
       "      <th>risk_score_4</th>\n",
       "      <th>risk_score_5</th>\n",
       "      <th>ext_quality_score</th>\n",
       "      <th>ext_quality_score_2</th>\n",
       "      <th>inquiries_last_month</th>\n",
       "      <th>e_signed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7629673</td>\n",
       "      <td>40</td>\n",
       "      <td>bi-weekly</td>\n",
       "      <td>1</td>\n",
       "      <td>3135</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>550</td>\n",
       "      <td>36200</td>\n",
       "      <td>0.737398</td>\n",
       "      <td>0.903517</td>\n",
       "      <td>0.487712</td>\n",
       "      <td>0.515977</td>\n",
       "      <td>0.580918</td>\n",
       "      <td>0.380918</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3560428</td>\n",
       "      <td>61</td>\n",
       "      <td>weekly</td>\n",
       "      <td>0</td>\n",
       "      <td>3180</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>600</td>\n",
       "      <td>30150</td>\n",
       "      <td>0.738510</td>\n",
       "      <td>0.881027</td>\n",
       "      <td>0.713423</td>\n",
       "      <td>0.826402</td>\n",
       "      <td>0.730720</td>\n",
       "      <td>0.630720</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  age pay_schedule  home_owner  income  months_employed  \\\n",
       "0   7629673   40    bi-weekly           1    3135                0   \n",
       "1   3560428   61       weekly           0    3180                0   \n",
       "\n",
       "   years_employed  current_address_year  personal_account_m  \\\n",
       "0               3                     3                   6   \n",
       "1               6                     3                   2   \n",
       "\n",
       "   personal_account_y  ...  amount_requested  risk_score  risk_score_2  \\\n",
       "0                   2  ...               550       36200      0.737398   \n",
       "1                   7  ...               600       30150      0.738510   \n",
       "\n",
       "   risk_score_3  risk_score_4  risk_score_5  ext_quality_score  \\\n",
       "0      0.903517      0.487712      0.515977           0.580918   \n",
       "1      0.881027      0.713423      0.826402           0.730720   \n",
       "\n",
       "   ext_quality_score_2  inquiries_last_month  e_signed  \n",
       "0             0.380918                    10         1  \n",
       "1             0.630720                     9         0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a2b28f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'e_signed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'e_signed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43me_signed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'e_signed'"
     ]
    }
   ],
   "source": [
    "dataset['e_signed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b55b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "dataset = dataset.drop(columns = ['months_employed'])\n",
    "dataset['personal_account_months'] = (dataset.personal_account_m + (dataset.personal_account_y * 12))\n",
    "dataset[['personal_account_m', 'personal_account_y', 'personal_account_months']].head()\n",
    "dataset = dataset.drop(columns = ['personal_account_m', 'personal_account_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5671fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "dataset = pd.get_dummies(dataset)\n",
    "dataset.columns\n",
    "dataset = dataset.drop(columns = ['pay_schedule_semi-monthly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea04f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing extra columns\n",
    "response = dataset[\"e_signed\"]\n",
    "users = dataset['entry_id']\n",
    "dataset = dataset.drop(columns = [\"e_signed\", \"entry_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dfbdd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9639\n",
       "0    8269\n",
       "Name: e_signed, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a96bd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17908, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d254215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into Train and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset,\n",
    "                                                    response,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84cc3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e57f4bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5957    0\n",
       "Name: e_signed, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcdfbfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression (Lasso)</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>0.634817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Linear Regression (Lasso)  0.562535   0.576386  0.706432  0.634817"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, penalty = 'l2')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = pd.DataFrame([['Linear Regression (Lasso)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6746345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHES\\AppData\\Local\\Temp\\ipykernel_21560\\3329615971.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(model_results, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "## SVM (Linear)\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(random_state = 0, kernel = 'linear')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9b9d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression (Lasso)</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>0.634817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.568398</td>\n",
       "      <td>0.577832</td>\n",
       "      <td>0.735477</td>\n",
       "      <td>0.647193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Linear Regression (Lasso)  0.562535   0.576386  0.706432  0.634817\n",
       "1               SVM (Linear)  0.568398   0.577832  0.735477  0.647193"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c70913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHES\\AppData\\Local\\Temp\\ipykernel_21560\\680761211.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(model_results, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "## SVM (rbf)\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(random_state = 0, kernel = 'rbf')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['SVM (RBF)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b63b84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression (Lasso)</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>0.634817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.568398</td>\n",
       "      <td>0.577832</td>\n",
       "      <td>0.735477</td>\n",
       "      <td>0.647193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.591569</td>\n",
       "      <td>0.605730</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.645505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Linear Regression (Lasso)  0.562535   0.576386  0.706432  0.634817\n",
       "1               SVM (Linear)  0.568398   0.577832  0.735477  0.647193\n",
       "2                  SVM (RBF)  0.591569   0.605730  0.690871  0.645505"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c483442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHES\\AppData\\Local\\Temp\\ipykernel_21560\\3699315553.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(model_results, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "## RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n",
    "                                    criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest (n=100)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df966a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression (Lasso)</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>0.634817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.568398</td>\n",
       "      <td>0.577832</td>\n",
       "      <td>0.735477</td>\n",
       "      <td>0.647193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.591569</td>\n",
       "      <td>0.605730</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.645505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest (n=100)</td>\n",
       "      <td>0.621720</td>\n",
       "      <td>0.640098</td>\n",
       "      <td>0.678942</td>\n",
       "      <td>0.658948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Linear Regression (Lasso)  0.562535   0.576386  0.706432  0.634817\n",
       "1               SVM (Linear)  0.568398   0.577832  0.735477  0.647193\n",
       "2                  SVM (RBF)  0.591569   0.605730  0.690871  0.645505\n",
       "3      Random Forest (n=100)  0.621720   0.640098  0.678942  0.658948"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6335a3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.63 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "## K-fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X= X_train, y = y_train,\n",
    "                             cv = 10)\n",
    "print(\"Random Forest Classifier Accuracy: %0.2f (+/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "137f40a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Parameter Tuning\n",
    "# pip install joblib\n",
    "# conda install joblib\n",
    "\n",
    "# Applying Grid Search\n",
    "\n",
    "# Round 1: Entropy\n",
    "parameters = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 5, 10],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 5, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"entropy\"]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
    "\n",
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy, rf_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 2: Entropy\n",
    "parameters = {\"max_depth\": [None],\n",
    "              \"max_features\": [3, 5, 7],\n",
    "              'min_samples_split': [8, 10, 12],\n",
    "              'min_samples_leaf': [1, 2, 3],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"entropy\"]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
    "\n",
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy, rf_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Test Set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest (n=100, GSx2 + Entropy)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 1: Gini\n",
    "parameters = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 5, 10],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 5, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
    "\n",
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy, rf_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cef374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 2: Gini\n",
    "parameters = {\"max_depth\": [None],\n",
    "              \"max_features\": [8, 10, 12],\n",
    "              'min_samples_split': [2, 3, 4],\n",
    "              'min_samples_leaf': [8, 10, 12],\n",
    "              \"bootstrap\": [True],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
    "\n",
    "rf_best_accuracy = grid_search.best_score_\n",
    "rf_best_parameters = grid_search.best_params_\n",
    "rf_best_accuracy, rf_best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99105c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Test Set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest (n=100, GSx2 + Gini)', acc, prec, rec, f1]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
